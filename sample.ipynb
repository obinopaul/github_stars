{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eb02c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from pprint import pprint\n",
    "\n",
    "GEMINI_API_KEY = \"\"\n",
    "\n",
    "# Initialize Gemini 2.5 Pro chat model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Create a prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\"Question: {question}\\nAnswer:\")\n",
    "\n",
    "# Build the workflow chain\n",
    "chain = RunnableSequence(prompt | llm | StrOutputParser())\n",
    "\n",
    "# Function to ask a question and pretty print the answer\n",
    "def ask_gemini(question):\n",
    "    answer = chain.invoke({\"question\": question})\n",
    "    pprint(answer)\n",
    "\n",
    "# Read the content from the markdown file and extract it as a string\n",
    "def extract_text_from_markdown(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "# Example usage\n",
    "file_path = 'input_text.md'  # Path to your markdown file\n",
    "input_text = extract_text_from_markdown(file_path)\n",
    "\n",
    "# # Now, you can use this string in your Langchain code or pass it to your AI model\n",
    "# print(input_text)  # Just to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c0d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb599861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('```markdown\\n'\n",
      " '### NVIDIA AI Blueprint: Video Search and Summarization\\n'\n",
      " '**URL**: '\n",
      " '`https://github.com/NVIDIA-AI-Blueprints/video-search-and-summarization`\\n'\n",
      " '**Purpose**: An end-to-end blueprint for building AI agents that ingest '\n",
      " 'video streams to generate summaries and enable interactive Q&A. It '\n",
      " 'integrates NVIDIA NIMs for VLM, LLM, and ASR functionalities within a '\n",
      " 'containerized, microservice architecture.\\n'\n",
      " '**Key Components**:\\n'\n",
      " '*   **Context-Aware RAG (CA-RAG) Engine**: The core component (`vss-engine`) '\n",
      " 'implements a novel dual RAG strategy. It indexes VLM-generated captions, ASR '\n",
      " 'transcripts, and CV metadata into both a Milvus vector database and a Neo4j '\n",
      " 'graph database for enhanced temporal reasoning.\\n'\n",
      " '*   **TensorRT-Optimized CV Pipeline**: A reusable vision module '\n",
      " '(`src/vss-engine/src/cv_pipeline`) integrates a Grounded-SAM (GSAM) model '\n",
      " 'with DeepStream for efficient object detection and tracking, providing '\n",
      " 'structured metadata for the RAG system.\\n'\n",
      " '*   **Modular Deployment Configurations**: Reusable Docker Compose '\n",
      " '(`deploy/docker`) and Helm (`deploy/helm`) charts that define various '\n",
      " 'deployment topologies (local, remote, single-GPU), orchestrating the VSS '\n",
      " 'engine with required microservices.\\n'\n",
      " '*   **Gradio Video Timeline Component**: A custom Gradio UI component '\n",
      " '(`src/video_timeline`) for visualizing analysis results on an interactive '\n",
      " 'video timeline with timestamped event markers.\\n'\n",
      " '```')\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "result = ask_gemini(input_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
